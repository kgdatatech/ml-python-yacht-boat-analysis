{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17be1222",
   "metadata": {},
   "source": [
    "## A6.4 Supervised Machine Learning - Regression\n",
    "### The following script contains the following:\n",
    "\n",
    "#### 1. Import data, libraries, additional requirements\n",
    "#### 2. Data consistency checks\n",
    "#### 3. Data prep for regression analysis\n",
    "#### 4. Regression Analysis\n",
    "--------------------------------------------------\n",
    "### 1. Import libraries, additional requirements and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d85e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d02914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualizations in the notebook without the need to \"call\" them specifically\n",
    "%matplotlib inline\n",
    "\n",
    "# Turning off warning feature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56651c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create/save project folder path\n",
    "path = r\"C:\\Users\\keanu\\OneDrive\\Desktop\\Career Foundry\\Boat Sales Analysis\"\n",
    "\n",
    "# Read data (csv file)\n",
    "df = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'boat_sales_final.csv'), encoding='ISO-8859-1', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b7e72",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "### 2. Data consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836f2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc928df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant column\n",
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8015bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387a9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62319d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ef5e3",
   "metadata": {},
   "source": [
    "Notes: Nulls as expected, nulls kept instead of removing, as there can be a loss in valuable data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da048d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_dups = df[df.duplicated()] #no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097ab30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress scientific notation for easier analysis profiling\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c584b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute mean value of year for missing variables in 'Year Built' column as 5.57% Nans are relatively low and do not want to lose valuable information by removing Nans.\n",
    "mean_value = np.round(df['Year Built'].mean())\n",
    "\n",
    "# Fill missing values with the rounded mean\n",
    "df['Year Built'].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6d402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year Built'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0218af",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "### 3. Data prep for regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a89f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot to revisit how the chosen variables for your hypothesis plot against each other\n",
    "df.plot(x = 'Year Built', y='# of views last 7 days',style='o') # The style option creates a scatterplot; without it, we only have lines\n",
    "plt.title('Year Built vs # of Views Last 7 Days')  \n",
    "plt.xlabel('Year Built')  \n",
    "plt.ylabel('# of Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598f98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the variables into NumPy arrays and put them into separate objects\n",
    "X = df['Year Built'].values.reshape(-1,1)\n",
    "y = df['# of views last 7 days'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61bd0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded4cfd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4b3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650a5b9",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "### 4. Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db6074f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression object\n",
    "regression = LinearRegression()  # This is the regression object, which will be fit onto the training set\n",
    "\n",
    "# Import models that support missing values.\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "#regression = HistGradientBoostingRegressor() # Used instead, in order to preserve nan values/multiple regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b2921fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regression object onto the training set\n",
    "regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b4a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values of y using X\n",
    "y_predicted = regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c115fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot that shows the regression line from the model on the test set\n",
    "plot_test = plt\n",
    "plot_test.scatter(X_test, y_test, color='skyblue', s = 15)\n",
    "plot_test.plot(X_test, y_predicted, color='orange', linewidth =3)\n",
    "plot_test.title('Year Built vs # of Views Last 7 Days (Test set)')\n",
    "plot_test.xlabel('Year Built')\n",
    "plot_test.ylabel('# of Views Last 7 Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fcc1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects that contain the model summary statistics\n",
    "rmse = mean_squared_error(y_test, y_predicted) # This is the mean squared error\n",
    "r2 = r2_score(y_test, y_predicted) # This is the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8739694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary statistics. This is where you evaluate the performance of the model\n",
    "print('Slope:' ,regression.coef_)\n",
    "print('Mean squared error: ', rmse)\n",
    "print('R2 score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "483bd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "581af18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe comparing the actual and predicted values of y\n",
    "data = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_predicted.flatten()})\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6a83a",
   "metadata": {},
   "source": [
    "##### Compare how the regression fits the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6781d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_predicted_train = regression.predict(X_train) # This is predicting X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f06ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_train, y_predicted_train)\n",
    "r2 = r2_score(y_train, y_predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7303b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope:' ,regression.coef_)\n",
    "print('Mean squared error: ', rmse)\n",
    "print('R2 score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82f851e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training set results\n",
    "plot_test = plt\n",
    "plot_test.scatter(X_train, y_train, color='seagreen', s = 15)\n",
    "plot_test.plot(X_train, y_predicted_train, color='orange', linewidth =3)\n",
    "plot_test.title('Year Built vs # of Views Last 7 Days (Train set)')\n",
    "plot_test.xlabel('Year Built')\n",
    "plot_test.ylabel('# of Views Last 7 Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dceab3d",
   "metadata": {},
   "source": [
    "### Model Summary:\n",
    "- Slope: -1.0446\n",
    "- Indicates a negative relationship between the independent and dependent variables.\n",
    "\n",
    "#### Mean Squared Error (MSE):\n",
    "- MSE1: 20086.42\n",
    "- MSE2: 23898.96\n",
    "- High MSE suggests significant prediction errors compared to actual values.\n",
    "\n",
    "#### R-squared (R2) Score:\n",
    "- R21: 0.0167\n",
    "- R22: 0.0111\n",
    "- Low R2 scores indicate limited explanatory power of the model.\n",
    "\n",
    "#### Interpretation:\n",
    "- The linear regression model struggles to predict the dependent variable accurately.\n",
    "- Negative slope suggests a negative relationship.\n",
    "- Low R2 scores and high MSE indicate room for improvement in model performance.\n",
    "\n",
    "#### Recommendations:\n",
    "- Consider model refinement, or exploring alternative models for improved accuracy.\n",
    "\n",
    "\n",
    "### Limitations and Potential Data Bias:\n",
    "1. The number of views data can be influenced by various factors in this dataset, such as price and year built, though not directly. This suggests that website views may be influenced by factors beyond this dataset, such as how the website displays its yacht and boat selling posts to consumers, time of day online, and season of year. This implies a broader range of influences on the number of views.\n",
    "\n",
    "2. Potential biases in the dataset include human error, missing variables, imputation of missing variables, and the removal of extreme values. Dealing with NaN values in this dataset was challenging to avoid introducing additional bias to the analysis.\n",
    "\n",
    "3. Extreme values were not removed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
